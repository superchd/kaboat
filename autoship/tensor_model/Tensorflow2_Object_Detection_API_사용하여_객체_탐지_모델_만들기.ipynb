{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow2 Object Detection API 사용하여 객체 탐지 모델 만들기.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJurtO2MNjhi"
      },
      "source": [
        "# Tensorflow2 Object Detection API 사용하여 객체 탐지 모델 만들기\n",
        "지금부터 Tensorflow2 Object Detection API를 사용하여 사용자 지정 데이터에 대한 객체 탐지 모델을 만들도록 하겠습니다.\n",
        "\n",
        "작업을 시작하기 위해서 학습할 이미지 사진과 라벨링 정보가 들어있는 xml 파일이 필요합니다.\n",
        "\n",
        "우선 부표와 작은공을 학습시킬 예정이지만 주석으로 표시한 부분을 수정하면 다른 데이터로 학습시킬 수 있습니다.\n",
        "\n",
        "작업을 시작하기에 앞서 빠른 환경에서 작업하기 위해 GPU를 사용하도록 설정합니다.\n",
        "\n",
        "런타임 > 런타임 유형 변경 > 하드웨어 가속기 > GPU \n",
        "\n",
        "설정이 끝났으면 본격적으로 시작합니다.\n",
        "\n",
        "( 참고 : https://ichi.pro/ko/tensorflow-gaegche-gamji-gaideu-tensorflow-2-252181752953859 )\n",
        "\n",
        "( 전반적인 내용은 위 링크를 참고하여 작성하였습니다. )\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO9ufkiN5Ijy"
      },
      "source": [
        "구글 드라이브와 연결하는 코드입니다.\n",
        "\n",
        "colab에서 생성한 파일들을 저장하고 최종적으로 생성된 모델 역시 이곳에 저장할 예정입니다.\n",
        "\n",
        "colab은 일정시간 이후 런타임이 끊어지게 되는데 런타임이 끊어질 경우 드라이브에 업로드 하지 않은 파일들은 전부 사라지게 됩니다.\n",
        "\n",
        "그러므로 한번에 모든 작업을 실행하기보단 작업 중간중간 생성된 파일들을 드라이브에 저장해가면서 작업하는 것을 추천합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVHRkq6gjS7W"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1jk0r0xb4GC"
      },
      "source": [
        "각종 파일을 다운로드할 워크스페이스를 생성합니다.\n",
        "\n",
        "드라이브에도 생성된 파일들을 저장할 폴더를 미리 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ZVXpnl_byZL"
      },
      "source": [
        "%mkdir workspace\n",
        "%mkdir /content/drive/MyDrive/shipdata_tf/data /content/drive/MyDrive/shipdata_tf/my_model\n",
        "%cd /content/workspace"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPRWMgFggdjN"
      },
      "source": [
        "Tensorflow2 Object Detection API를 포함하고 있는 모델을 다운로드합니다.\n",
        "\n",
        "Tensorflow2 Object Detection API는 객체 탐지 모델을 조금 더 간편하게 학습할 수 있도록 도와주는 API입니다.\n",
        "\n",
        "해당 모델은 객체 탐지 외에도 다양한 학습을 지원하고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnN4PZyeghq1"
      },
      "source": [
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuGFzEsuhc9Z"
      },
      "source": [
        "추가적으로 필요한 라이브러리를 설치하고 모델을 사용할 준비를 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8SDk4m7gtsn"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -qq pycocotools\n",
        "%cd models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zE7IGI-Yhl48"
      },
      "source": [
        "모델이 제대로 준비되었는지 테스트합니다.\n",
        "\n",
        "마지막에 OK가 출력되면 정상적으로 준비된 것입니다.\n",
        "\n",
        "(시간이 오래 걸립니다.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzUOqiSPg5Bz"
      },
      "source": [
        "%cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install .\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EK3YouhSKCV3"
      },
      "source": [
        "라벨링 파일들을 구글 드라이브에 업로드 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpnRnq6lKBe3"
      },
      "source": [
        "# 업로드한 사진, xml 파일 위치\n",
        "drive_img = '/content/drive/MyDrive/shipdata_tf/img'\n",
        "drive_xml = '/content/drive/MyDrive/shipdata_tf/xml'\n",
        "\n",
        "# 생성할 csv, record 파일 위치\n",
        "drive_csv = '/content/drive/MyDrive/shipdata_tf/data/labels.csv'\n",
        "drive_tfrecord = '/content/drive/MyDrive/shipdata_tf/data/train.tfrecord'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlnKy0KmKnU6"
      },
      "source": [
        "업로드한 xml 파일들을 하나의 csv 파일로 통합합니다.\n",
        "\n",
        "( 참고 : https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/xml_to_csv.py )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZ4r3nJKsR_"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main(drive_xml, drive_csv):\n",
        "\txml_df = xml_to_csv(drive_xml)\n",
        "\txml_df.to_csv(drive_csv, index=None)\n",
        "\n",
        "\n",
        "main(drive_xml, drive_csv)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OrWDYF-jhzVq"
      },
      "source": [
        "라벨링 파일을 Tensorflow에서 학습시킬 수 있는 tfrecord 파일로 만들어주는 코드를 실행합니다.\n",
        "\n",
        "코드 중간에 클래스 이름을 본인에게 맞는 클래스 이름으로 수정해야 합니다.\n",
        "\n",
        "( 참고 : https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/generate_tfrecord.py )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn07zUBIJvN2"
      },
      "source": [
        "#based on https://github.com/datitran/raccoon_dataset/blob/master/generate_tfrecord.py\n",
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import sys\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.python.framework.versions import VERSION\n",
        "if VERSION >= \"2.0.0a0\":\n",
        "    import tensorflow.compat.v1 as tf\n",
        "else:\n",
        "    import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "\n",
        "CSV = drive_csv\n",
        "RECORD = drive_record\n",
        "IMG = drive_img\n",
        "\n",
        "\n",
        "# 클래스 이름 수정\n",
        "def class_text_to_int(row_label):\n",
        "    if row_label == 'buoy':\n",
        "        return 1\n",
        "    elif row_label == 'smallball':\n",
        "        return 2\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main():\n",
        "    writer = tf.python_io.TFRecordWriter(RECORD)\n",
        "    path = os.path.join(IMG)\n",
        "    examples = pd.read_csv(CSV)\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    print('Successfully created the TFRecords: {}'.format(RECORD))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGABRVryhy7p"
      },
      "source": [
        "학습에 필요한 파일들을 저장할 폴더를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rh5Azlnbh5qe"
      },
      "source": [
        "%cd /content/workspace/\n",
        "%mkdir annotations exported-models pre-trained-models models/my_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skY783UXitVz"
      },
      "source": [
        "미리 학습된 모델을 다운로드 합니다.\n",
        "\n",
        "이 과정은 객체 탐지 모델의 정확도와 인식 속도를 향상시켜줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ty-kofEsir3A"
      },
      "source": [
        "import tarfile\n",
        "import os\n",
        "\n",
        "%cd pre-trained-models\n",
        "!curl \"http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\" --output \"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\"\n",
        "\n",
        "model_file = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "tar = tarfile.open(model_file)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "os.remove(model_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVlkfJpHCbFK"
      },
      "source": [
        "클래스 이름에 관한 내용이 저장된 pbtxt 파일을 생성하고 드라이브에 업로드 합니다.\n",
        "\n",
        "pbtxt 파일의 형식은 아래를 참고합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ECy6cUcCyYq"
      },
      "source": [
        "'''\n",
        "# labels.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'buoy'\n",
        "}\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'smallball'\n",
        "}\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgRdPoi9C-gD"
      },
      "source": [
        "학습에 사용할 tfrecord 파일과 pbtxt 파일을 작업공간에 복사합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFtiAfqsDLzQ"
      },
      "source": [
        "# 업로드한 pbtxt 파일 위치\n",
        "drive_pbtxt = '/content/drive/MyDrive/shipdata_tf/data/labels.pbtxt'\n",
        "\n",
        "%cp $drive_record /content/workspace/annotations/train.tfrecord\n",
        "%cp $drive_pbtxt /content/workspace/annotations/labels.pbtxt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSWlDIhRjVVY"
      },
      "source": [
        "학습과 관련된 내용은 pipeline.config 파일에 저장되어 있습니다.\n",
        "\n",
        "이 파일을 살펴보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTBuXVK3jc9l"
      },
      "source": [
        "%cat ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgTUarXLoKyM"
      },
      "source": [
        "colab에서는 해당 파일을 더블클릭하여 수정할 수 있습니다.\n",
        "\n",
        "수정할 내용은 아래를 참고합니다.\n",
        "\n",
        "수정이 끝난 후 Ctrl + s 로 저장할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK1MG3uyD-LE"
      },
      "source": [
        "'''\n",
        "# pipeline.config\n",
        "# 학습시킬 클래스의 개수\n",
        "num_classes: 2\n",
        "\n",
        "# 한번에 학습시킬 묶음\n",
        "# 너무 클 경우 과부화가 발생합니다.\n",
        "batch_size: 8\n",
        "\n",
        "# 중간 저장 위치\n",
        "fine_tune_checkpoint: \"/content/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
        "\n",
        "# 총 학습시킬 횟수\n",
        "# 25000번 정도 학습하는 것을 권장합니다.\n",
        "num_steps: 25000\n",
        "\n",
        "# 중간 저장\n",
        "fine_tune_checkpoint_type: \"detection\"\n",
        "\n",
        "# \"PATH_TO_BE_CONFIGURED\" 부분을 본인의 경로에 맞게 수정합니다.\n",
        "# 각각 2줄씩 총 4줄을 수정합니다.\n",
        "# 작업공간에 복사한 pbtxt 파일 위치\n",
        "label_map_path: \"/content/workspace/annotations/labels.pbtxt\"\n",
        "\n",
        "# 작업공간에 복사한 record 파일 위치\n",
        "input_path: \"/content/workspace/annotations/train.tfrecord\"\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woQS55GoE27V"
      },
      "source": [
        "수정이 끝난 후 잘 저장되었나 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u_MxQ4To94F"
      },
      "source": [
        "%cat /content/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj80KhDjE_-b"
      },
      "source": [
        "학습을 진행하기 위해 환경변수를 지정합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0BjXupbpteF"
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/workspace/models/:/content/workspace/models/research/:/content/workspace/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy2PLl67FFiH"
      },
      "source": [
        "학습 진행 상황을 확인할 수 있는 텐서보드를 로딩합니다.\n",
        "\n",
        "처음에는 빈화면이 나오지만 학습을 진행한 후 우측 상단의 새로고침을 누르면 학습 현황이 시각적으로 나타납니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y8rcRFuqG1R"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/workspace/models/my_data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GgF7NDnFbcE"
      },
      "source": [
        "학습 실행파일을 실행하기 편한 위치로 복사합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAeGv2gNq315"
      },
      "source": [
        "%cd /content/workspace\n",
        "!cp '/content/workspace/models/research/object_detection/model_main_tf2.py' ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMfCAyh6FiJG"
      },
      "source": [
        "학습을 진행합니다.\n",
        "\n",
        "30분 정도 걸렸습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OfsB8HVrXTB"
      },
      "source": [
        "!python model_main_tf2.py --model_dir=models/my_data --pipeline_config_path=/content/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkWmUiMYO-lF"
      },
      "source": [
        "가장 마지막 체크포인트만 저장합니다.\n",
        "\n",
        "( 참고 : https://gist.github.com/rohitp934/8b1918bf3f13545bf667f86f2af77a6d#file-getlatestcheckpoint-py )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVnjuQBg-2l5"
      },
      "source": [
        "import numpy as np\n",
        "import re\n",
        "\n",
        "output_directory = '/content/workspace/exported-models/'\n",
        "\n",
        "lst = os.listdir(\"/content/workspace/models/my_data/\")\n",
        "\n",
        "lst = [l for l in lst if 'ckpt-' in l and '.index' not in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()]\n",
        "last_model_path = os.path.join('/content/workspace/models/my_data', last_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArQ2dE8oPasK"
      },
      "source": [
        "마지막 체크포인트에서 데이터를 추출하여 모델을 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhePoRvb7ag6"
      },
      "source": [
        "!python /content/workspace/models/research/object_detection/exporter_main_v2.py \\\n",
        "--input_type=image_tensor \\\n",
        "--pipeline_config_path=/content/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--output_directory=/content/drive/MyDrive/shipdata_tf/my_model \\\n",
        "--trained_checkpoint_dir=/content/workspace/models/my_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWzZ0IiEP2cL"
      },
      "source": [
        "모델이 잘 학습되었는지 확인합니다.\n",
        "\n",
        "( 참고 : https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb#scrollTo=EEX-m3P1yp4y )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI8geZPHBHW2"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "category_index = label_map_util.create_category_index_from_labelmap(drive_pbtxt, use_display_name=True)\n",
        "tf.keras.backend.clear_session()\n",
        "# 모델 저장한 경로\n",
        "model = tf.saved_model.load(f'/content/drive/MyDrive/shipdata_tf/my_model/saved_model')\n",
        "\n",
        "\n",
        "def run_inference_for_single_image(model, image):\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy() \n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "   \n",
        "  if 'detection_masks' in output_dict:\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "    \n",
        "  return output_dict\n",
        "\n",
        "\n",
        "# 테스트용 이미지 경로\n",
        "for image_path in glob.glob('/content/drive/MyDrive/shipdata_tf/img/buoy1.jpg'):\n",
        "  image_np = load_image_into_numpy_array(image_path)\n",
        "  output_dict = run_inference_for_single_image(model, image_np)\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=8)\n",
        "  display(Image.fromarray(image_np))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQmHMzdImKvm"
      },
      "source": [
        "학습시킨 Tensorflow 모델을 Jetson nano에서 사용하기 위해 더욱 가벼운 모델인 Tensorflow lite 모델로 변환합니다.\n",
        "\n",
        "( 참고 : https://www.tensorflow.org/lite/convert/?hl=ko )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSCuiJ_LaSEz"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# 모델 저장한 경로\n",
        "saved_model_dir = '/content/drive/MyDrive/shipdata_tf/saved_model/saved_model'\n",
        "\n",
        "model = tf.saved_model.load(saved_model_dir)\n",
        "model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY].inputs[0].set_shape([1, 320, 320, 3])\n",
        "tf.saved_model.save(model, \"saved_model_updated\", signatures=model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY])\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='saved_model_updated', signature_keys=['serving_default'])\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "input_shape = input_details[0]['shape']\n",
        "print(input_shape)\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgNo242cyRMo"
      },
      "source": [
        "만약 위 코드 실행중 오류 발생 시 모델 폴더(saved_model)를 다운로드한 후 밑의 내용을 커멘드 창에 입력합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU4_7qiRyjNI"
      },
      "source": [
        "'''\n",
        "tflite_convert \\\n",
        "  # 모델 저장된 위치\n",
        "  --saved_model_dir=/tmp/mobilenet_saved_model \\\n",
        "  # 모델 저장할 위치\n",
        "  --output_file=/tmp/mobilenet.tflite\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlfzmhXZynW-"
      },
      "source": [
        "여기까지 잘 실행했다면 성공적으로 .tflite 파일이 생성되었을 것입니다.\n",
        "\n",
        "이를 다운받아서 사용하면 됩니다."
      ]
    }
  ]
}